{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Session(region_name='eu-central-1')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "session = boto3.Session() # Grabs session details directly from aws configuration in EC2 instance running the Notebook server\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s3.ServiceResource()"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3r = session.resource(\"s3\")\n",
    "s3r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-110-c6844b4121f5>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-110-c6844b4121f5>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    #print(bucket)\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#for bucket in s3r.buckets.all():\n",
    "  #print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covid-19/1/owid-covid-data.csv\n",
      "Covid-19/2/covid-19-at.csv\n",
      "Covid-19/2/covid-19-be.csv\n",
      "Covid-19/2/covid-19-ch.csv\n",
      "Covid-19/2/covid-19-cz.csv\n",
      "Covid-19/2/covid-19-de.csv\n",
      "Covid-19/2/covid-19-ecdc.csv\n",
      "Covid-19/2/covid-19-england.csv\n",
      "Covid-19/2/covid-19-fr.csv\n",
      "Covid-19/2/covid-19-hu.csv\n",
      "Covid-19/2/covid-19-ie.csv\n",
      "Covid-19/2/covid-19-it.csv\n",
      "Covid-19/2/covid-19-nl.csv\n",
      "Covid-19/2/covid-19-no.csv\n",
      "Covid-19/2/covid-19-pl.csv\n",
      "Covid-19/2/covid-19-scotland.csv\n",
      "Covid-19/2/covid-19-se.csv\n",
      "Covid-19/2/covid-19-si.csv\n",
      "Covid-19/2/covid-19-uk.csv\n",
      "Covid-19/2/covid-19-wales.csv\n",
      "Covid-19/3/time_series_covid19_confirmed_US.csv\n",
      "Covid-19/3/time_series_covid19_confirmed_global.csv\n",
      "Covid-19/3/time_series_covid19_deaths_US.csv\n",
      "Covid-19/3/time_series_covid19_deaths_global.csv\n",
      "Covid-19/3/time_series_covid19_recovered_global.csv\n",
      "Covid-19/4/covid_jpn_metadata.csv\n",
      "Covid-19/4/covid_jpn_prefecture.csv\n",
      "Covid-19/4/covid_jpn_total.csv\n",
      "Covid-19/5/brazil_cities_coordinates.csv\n",
      "Covid-19/5/brazil_covid19.csv\n",
      "Covid-19/5/brazil_covid19_cities.csv\n",
      "Covid-19/5/brazil_covid19_macro.csv\n",
      "Covid-19/5/brazil_covid19_old.csv\n",
      "Covid-19/5/brazil_population_2019.csv\n",
      "Covid-19/6/StatewiseTestingDetails.csv\n",
      "Covid-19/6/covid_19_india.csv\n",
      "Covid-19/output/country_details.csv\n",
      "Covid-19/output/owid_clean.csv\n",
      "Covid-19/output/predictions_for_tableau.csv\n"
     ]
    }
   ],
   "source": [
    "bucket = s3r.Bucket('aida-project')\n",
    "files=[]\n",
    "for obj in bucket.objects.all():\n",
    "  if obj.key.startswith(\"Covid\"):\n",
    "   # print(obj.key)\n",
    "    if obj.key.endswith(\"csv\"):\n",
    "        files.append(obj.key)\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_investigate(df):\n",
    "  info = pd.DataFrame(df.count(), columns=['filled'])\n",
    "  info['filled %'] = round(info['filled'] / len(df), 4)*100\n",
    "  info['nunique'] = df.nunique()\n",
    "  info['uniques'] = np.nan\n",
    "  info['dtypes'] = df.dtypes\n",
    "  for idx, row in info.iterrows():\n",
    "    if row['nunique'] < 10:\n",
    "      info.loc[idx, 'uniques'] = str(list(df[idx].unique()))\n",
    "  return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1282: expected 8 fields, saw 9\\nSkipping line 1283: expected 8 fields, saw 9\\nSkipping line 1293: expected 8 fields, saw 9\\nSkipping line 1294: expected 8 fields, saw 9\\nSkipping line 1300: expected 8 fields, saw 9\\nSkipping line 1308: expected 8 fields, saw 9\\nSkipping line 1309: expected 8 fields, saw 9\\nSkipping line 1314: expected 8 fields, saw 9\\nSkipping line 1319: expected 8 fields, saw 9\\nSkipping line 1320: expected 8 fields, saw 9\\nSkipping line 1321: expected 8 fields, saw 9\\nSkipping line 1323: expected 8 fields, saw 9\\n'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "cols={}\n",
    "investigation={}\n",
    "for i in range(len(files)):\n",
    "    nstars=62 - len(files[i])\n",
    "    #print((nstars + 4)*'*')\n",
    "    #print('* ',files[i],' *')\n",
    "    #print((nstars + 4)*'*')\n",
    "    file_check = \"s3://\" + bucket.name + \"/\" + files[i]\n",
    "\n",
    "    # get the training data\n",
    "    df = pd.read_csv(file_check, error_bad_lines=False)\n",
    "    \n",
    "    \"\"\"\n",
    "    print(df.head(3))\n",
    "    print(\"\\n\",30*'=')\n",
    "    print('   Investigation')\n",
    "    print(30*'=',\"\\n\")\n",
    "    \"\"\"\n",
    "    \n",
    "    inv = df_investigate(df)\n",
    "    #print(files[i])\n",
    "    #print(inv)\n",
    "    \n",
    "    investigation[files[i]]=inv\n",
    "    #print(investigation)\n",
    "    cols[files[i]] = df.columns.values.tolist()\n",
    "    # print(cols)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covid-19/5/brazil_cities_coordinates.csv \n",
      " ['state_code', 'city_code', 'city_name', 'lat', 'long', 'capital']\n",
      "Covid-19/5/brazil_covid19.csv \n",
      " ['date', 'region', 'state', 'cases', 'deaths']\n",
      "Covid-19/5/brazil_covid19_cities.csv \n",
      " ['date', 'state', 'name', 'code', 'cases', 'deaths']\n",
      "Covid-19/5/brazil_covid19_macro.csv \n",
      " ['date', 'country', 'week', 'cases', 'deaths', 'recovered', 'monitoring']\n",
      "Covid-19/5/brazil_covid19_old.csv \n",
      " ['date', 'hour', 'state', 'suspects', 'refuses', 'cases', 'deaths']\n",
      "Covid-19/5/brazil_population_2019.csv \n",
      " ['region', 'state', 'city', 'state_code', 'city_code', 'health_region_code', 'health_region', 'population']\n"
     ]
    }
   ],
   "source": [
    "# link2: 1,20\n",
    "# link3: 20,25\n",
    "# link4: 25,28\n",
    "# link5: 28,34\n",
    "# link6: 34,36\n",
    "\n",
    "\n",
    "\n",
    "for i in range(28,34):\n",
    "    print(files[i],\"\\n\",cols[files[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filled</th>\n",
       "      <th>filled %</th>\n",
       "      <th>nunique</th>\n",
       "      <th>uniques</th>\n",
       "      <th>dtypes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>141580</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "      <td>['NL']</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lau</th>\n",
       "      <td>141467</td>\n",
       "      <td>99.92</td>\n",
       "      <td>369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cases</th>\n",
       "      <td>135916</td>\n",
       "      <td>96.00</td>\n",
       "      <td>1357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>139030</td>\n",
       "      <td>98.20</td>\n",
       "      <td>1084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cases/100k pop.</th>\n",
       "      <td>4970</td>\n",
       "      <td>3.51</td>\n",
       "      <td>1070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deaths</th>\n",
       "      <td>141580</td>\n",
       "      <td>100.00</td>\n",
       "      <td>157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitalized</th>\n",
       "      <td>134173</td>\n",
       "      <td>94.77</td>\n",
       "      <td>792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitalized/100k pop.</th>\n",
       "      <td>2832</td>\n",
       "      <td>2.00</td>\n",
       "      <td>447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <td>141580</td>\n",
       "      <td>100.00</td>\n",
       "      <td>164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filled  filled %  nunique uniques   dtypes\n",
       "country                 141580    100.00        1  ['NL']   object\n",
       "lau                     141467     99.92      369     NaN   object\n",
       "cases                   135916     96.00     1357     NaN  float64\n",
       "population              139030     98.20     1084     NaN  float64\n",
       "cases/100k pop.           4970      3.51     1070     NaN  float64\n",
       "deaths                  141580    100.00      157     NaN    int64\n",
       "hospitalized            134173     94.77      792     NaN  float64\n",
       "hospitalized/100k pop.    2832      2.00      447     NaN  float64\n",
       "datetime                141580    100.00      164     NaN   object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investigation['Covid-19/2/covid-19-nl.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Owid Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>continent</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smoothed</th>\n",
       "      <th>...</th>\n",
       "      <th>gdp_per_capita</th>\n",
       "      <th>extreme_poverty</th>\n",
       "      <th>cardiovasc_death_rate</th>\n",
       "      <th>diabetes_prevalence</th>\n",
       "      <th>female_smokers</th>\n",
       "      <th>male_smokers</th>\n",
       "      <th>handwashing_facilities</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>human_development_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABW</td>\n",
       "      <td>North America</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35973.781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABW</td>\n",
       "      <td>North America</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35973.781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABW</td>\n",
       "      <td>North America</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35973.781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABW</td>\n",
       "      <td>North America</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35973.781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABW</td>\n",
       "      <td>North America</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35973.781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso_code      continent location        date  total_cases  new_cases  \\\n",
       "0      ABW  North America    Aruba  2020-03-13          2.0        2.0   \n",
       "1      ABW  North America    Aruba  2020-03-19          NaN        NaN   \n",
       "2      ABW  North America    Aruba  2020-03-20          4.0        2.0   \n",
       "3      ABW  North America    Aruba  2020-03-21          NaN        NaN   \n",
       "4      ABW  North America    Aruba  2020-03-22          NaN        NaN   \n",
       "\n",
       "   new_cases_smoothed  total_deaths  new_deaths  new_deaths_smoothed  ...  \\\n",
       "0                 NaN           NaN         0.0                  NaN  ...   \n",
       "1               0.286           NaN         NaN                  0.0  ...   \n",
       "2               0.286           NaN         0.0                  0.0  ...   \n",
       "3               0.286           NaN         NaN                  0.0  ...   \n",
       "4               0.286           NaN         NaN                  0.0  ...   \n",
       "\n",
       "   gdp_per_capita  extreme_poverty  cardiovasc_death_rate  \\\n",
       "0       35973.781              NaN                    NaN   \n",
       "1       35973.781              NaN                    NaN   \n",
       "2       35973.781              NaN                    NaN   \n",
       "3       35973.781              NaN                    NaN   \n",
       "4       35973.781              NaN                    NaN   \n",
       "\n",
       "   diabetes_prevalence  female_smokers  male_smokers  handwashing_facilities  \\\n",
       "0                11.62             NaN           NaN                     NaN   \n",
       "1                11.62             NaN           NaN                     NaN   \n",
       "2                11.62             NaN           NaN                     NaN   \n",
       "3                11.62             NaN           NaN                     NaN   \n",
       "4                11.62             NaN           NaN                     NaN   \n",
       "\n",
       "   hospital_beds_per_thousand  life_expectancy  human_development_index  \n",
       "0                         NaN            76.29                      NaN  \n",
       "1                         NaN            76.29                      NaN  \n",
       "2                         NaN            76.29                      NaN  \n",
       "3                         NaN            76.29                      NaN  \n",
       "4                         NaN            76.29                      NaN  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data \n",
    "file_check = \"s3://\" + bucket.name + \"/\" + files[0]\n",
    "\n",
    "df_owid = pd.read_csv(file_check, error_bad_lines=False)\n",
    "df_owid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 'World' and 'International' out\n",
    "df_owid_clean_line = df_owid['location'].isin(['World','International'])\n",
    "#df_owid_clean_line = df_owid['location']=='International'\n",
    "df_owid_clean = df_owid.loc[~ df_owid_clean_line,:]\n",
    "#df_owid_clean['location'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_owid_clean.to_csv('owid_clean.csv', header=True, index=False)\n",
    "bucket.upload_file(Filename=\"owid_clean.csv\", Key='Covid-19/output/owid_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***********************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chris_Tabelle: country_details.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_cases -> new cases\n",
    "\n",
    "\n",
    "# create Dataframe\n",
    "# France\n",
    "df_country_details=pd.read_csv(\"s3://\" + bucket.name + \"/\" + files[8],error_bad_lines=False )\n",
    "df_country_details.columns =['country', 'lau', 'cases', 'datetime']\n",
    "\n",
    "# Germany\n",
    "df_dt=pd.read_csv(\"s3://\" + bucket.name + \"/\" + files[5],error_bad_lines=False )\n",
    "df_dt = df_dt.drop(columns= ['cases', 'datetime'], axis=1)\n",
    "df_dt.columns = ['country', 'lau', 'cases', 'datetime']\n",
    "df_country_details= pd.concat([df_country_details, df_dt], ignore_index=True)\n",
    "\n",
    "# Austria\n",
    "df_at=pd.read_csv(\"s3://\" + bucket.name + \"/\" + files[1],error_bad_lines=False )\n",
    "df_at = df_at.drop(columns= ['recovered', 'deaths', 'tests','hospitalized', 'intensive_care'], axis=1)\n",
    "df_at.columns = ['country', 'lau', 'cases', 'datetime']  \n",
    "df_country_details= pd.concat([df_country_details, df_at], ignore_index=True)\n",
    "\n",
    "\n",
    "# Belgium\n",
    "df_be=pd.read_csv(\"s3://\" + bucket.name + \"/\" + files[2],error_bad_lines=False )\n",
    "df_be = df_be.drop(columns= ['nuts_2',  'deaths', 'hospitalized','intensive_care',], axis=1)\n",
    "df_be.columns = ['country', 'lau', 'cases', 'datetime']\n",
    "df_country_details= pd.concat([df_country_details, df_be], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Switzerland\n",
    "df_ch=pd.read_csv(\"s3://\" + bucket.name + \"/\" + files[3],error_bad_lines=False )\n",
    "df_ch = df_ch.drop(columns= ['nuts_3_code', 'deaths', 'tests','hospitalized', 'intensive_care'], axis=1)\n",
    "df_ch.columns = ['country', 'lau', 'cases', 'datetime']\n",
    "df_country_details= pd.concat([df_country_details, df_ch], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france   (23885, 4)\n",
      "germany   (4560, 4)\n",
      "austria   (7278, 4)\n",
      "belgium   (3271, 4)\n",
      "switzerland   (8424, 4)\n",
      "new   (23885, 4)\n"
     ]
    }
   ],
   "source": [
    "print('france   '+str(df_country_details.shape))\n",
    "print('germany   '+str(df_dt.shape))\n",
    "print('austria   '+str(df_at.shape))\n",
    "print('belgium   '+str(df_be.shape))\n",
    "print('switzerland   '+str(df_ch.shape))\n",
    "\n",
    "print('new   '+ str(df_country_details.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# total_cases -> new cases\n",
    "# France\n",
    "df_fr=pd.read_csv(\"s3://\" + bucket.name + \"/\" + files[8],error_bad_lines=False )\n",
    "#df_a=pd.read_csv(\"s3://\" + bucket.name + \"/\" + files[7],error_bad_lines=False )\n",
    "\n",
    "# wie komme ich an den vorgänger entry ran?\n",
    "\n",
    "for i, entry in enumerate(df_fr['cases']):\n",
    "    if i>0:\n",
    "        if entry < df_fr['cases'][i-1]:\n",
    "            print(entry)\n",
    "            df_fr['cases'][i]=entry\n",
    "    else:\n",
    "        df_fr['cases'][i]\n",
    "        print(df_fr['cases'][i])\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "        df_fr['cases'][i]=entry\n",
    "    else:\n",
    "        df_fr['cases'][i]=df_fr.cases[i-1]-entry\n",
    "\n",
    "    i=+1\n",
    "    if i>10:\n",
    "        break\n",
    "\n",
    "# beispiel:\n",
    "a_list = [1,2,3,4,5]\n",
    "\n",
    "for index, elem in enumerate(a_list):\n",
    "    if (index+1 < len(a_list) and index - 1 >= 0):\n",
    "Check index bounds\n",
    "\n",
    "        prev_el = str(a_list[index-1])\n",
    "        curr_el = str(elem)\n",
    "        next_el = str(a_list[index+1])\n",
    "\n",
    "        print(prev_el, curr_el, next_el)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i, entry in enumerate(work):\\n    if entry:\\n        df.C[i] = accu\\n    else:\\n        accu = df.B[i]\\nprint(df)\\n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"A\":[1,1,1,2,2,2,1,1,1],\"B\":[2,5,12,1,1,1,18,2,2]})\n",
    "df[\"C\"] = df[\"B\"]\n",
    "work = df.A < df.B\n",
    "accu = df.B[0]\n",
    "print(df.B[0])\n",
    "'''\n",
    "for i, entry in enumerate(work):\n",
    "    if entry:\n",
    "        df.C[i] = accu\n",
    "    else:\n",
    "        accu = df.B[i]\n",
    "print(df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country                  nuts_3 nuts_3_code  cases  deaths  tests  \\\n",
      "0      CH                     NaN         NaN    0.0       0    4.0   \n",
      "1      CH                  Aargau          AG    NaN       0    NaN   \n",
      "2      CH   Appenzell Innerrhoden          AI    NaN       0    NaN   \n",
      "3      CH  Appenzell Ausserrhoden          AR    NaN       0    NaN   \n",
      "4      CH                   Berne          BE    NaN       0    NaN   \n",
      "\n",
      "   hospitalized  intensive_care    datetime  \n",
      "0           0.0             0.0  2020-01-24  \n",
      "1           NaN             NaN  2020-01-24  \n",
      "2           NaN             NaN  2020-01-24  \n",
      "3           NaN             NaN  2020-01-24  \n",
      "4           NaN             NaN  2020-01-24  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['country', 'nuts_3', 'nuts_3_code', 'cases', 'deaths', 'tests',\n",
       "       'hospitalized', 'intensive_care', 'datetime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join\n",
    "\n",
    "df_a=pd.read_csv(\"s3://\" + bucket.name + \"/\" + files[3],error_bad_lines=False )\n",
    "print(df_a.head())\n",
    "df_a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new   (23885, 4)\n"
     ]
    }
   ],
   "source": [
    "print('new   '+ str(df_country_details.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload csv to S3\n",
    "df_fr.to_csv('country_details.csv', header=True, index=False)\n",
    "bucket.upload_file(Filename=\"country_details.csv\", Key='Covid-19/output/country_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
